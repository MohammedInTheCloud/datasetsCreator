# LongPage Dataset Generator - Parallel Processing Configuration
# Copy this file to .env and customize the values for your needs

# =============================================================================
# LLM API Configuration
# =============================================================================

# Your Groq API key (required)
LLM_API_KEY=your_groq_api_key_here
GROQ_API_KEY=your_groq_api_key_here

# Model to use for LLM queries
LLM_MODEL=llama3-70b-8192

# API endpoint
LLM_BASE_URL=https://api.groq.com/openai/v1

# Alternative provider examples:
# For Ollama (local):
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_MODEL=llama3:70b
# LLM_API_KEY=any-value  # Ollama doesn't require real API key

# For LM Studio (local):
# LLM_BASE_URL=http://localhost:1234/v1
# LLM_MODEL=your-model-name
# LLM_API_KEY=any-value

# For OpenAI:
# LLM_BASE_URL=https://api.openai.com/v1
# LLM_MODEL=gpt-4-turbo
# LLM_API_KEY=your_openai_key

# Rate limiting and retry settings
MAX_RETRIES=3
RATE_LIMIT_DELAY=1.0

# =============================================================================
# Parallel Processing Configuration
# =============================================================================

# Global parallel processing switch (set to "true" to disable)
DISABLE_PARALLEL_PROCESSING=false

# Concurrency limits for different processing levels
MAX_CONCURRENT_BOOKS=3
MAX_CONCURRENT_CHAPTERS=5
MAX_CONCURRENT_SCENES=10
MAX_CONCURRENT_DIMENSIONS=7
MAX_CONCURRENT_EMBEDDING_CALLS=20

# Rate limiting for parallel operations
PARALLEL_RATE_LIMIT_DELAY=0.1

# =============================================================================
# Embedding Configuration
# =============================================================================

# Number of LLM calls to average for each embedding dimension
EMBEDDING_CALLS=16

# Embedding dimensions to analyze (comma-separated)
EMBEDDING_DIMENSIONS=action,dialog,world_building,exposition,romantic,erotic,pacing

# =============================================================================
# Pipeline Configuration
# =============================================================================

# Default input and output directories
BOOKS_DIR=D:\local\datasetsCreator\books
OUTPUT_DIR=D:\local\datasetsCreator\output

# Default processing limits
DEFAULT_MAX_BOOKS=100
DEFAULT_OUTPUT_FORMAT=jsonl

# =============================================================================
# Performance Tuning
# =============================================================================

# Memory usage settings
MAX_MEMORY_USAGE_MB=2048
CHUNK_SIZE=1000

# Timeout settings (seconds)
API_TIMEOUT=120
PROCESSING_TIMEOUT=3600

# =============================================================================
# Logging and Debugging
# =============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Enable detailed timing information
ENABLE_TIMING=true

# Enable progress bars
ENABLE_PROGRESS_BARS=true

# =============================================================================
# Advanced Configuration
# =============================================================================

# Fallback to sequential processing on failures
ENABLE_SEQUENTIAL_FALLBACK=true

# Batch processing settings
BATCH_SIZE=50
ENABLE_BATCH_PROCESSING=true

# Quality vs speed trade-offs
EMBEDDING_QUALITY=high  # high, medium, low
ENABLE_EMBEDDING_CACHING=false

# =============================================================================
# Development and Testing
# =============================================================================

# Enable test mode (processes fewer books, faster)
TEST_MODE=false
TEST_MAX_BOOKS=2

# Enable detailed debug output
DEBUG_MODE=false

# Profile processing times
ENABLE_PROFILING=false